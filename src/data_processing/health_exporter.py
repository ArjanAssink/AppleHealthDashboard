#!/usr/bin/env python3
"""
Health Data Exporter

Converts parsed HealthRecord objects into pre-aggregated JSON files
suitable for a browser-based HTML dashboard.

Output layout:
    output/
    ├── index.html                   (generated by html_dashboard.py)
    └── data/
        ├── manifest.json            (index of all available metrics)
        ├── workouts.json            (all workout records)
        └── metrics/
            └── {metric_id}.json     (daily/weekly/monthly agg per metric)
"""

import json
import re
from datetime import datetime, date, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple

import pandas as pd

from data_processing.health_parser import HealthRecord


# ---------------------------------------------------------------------------
# Apple Health type metadata
# ---------------------------------------------------------------------------

# For quantity types the aggregation method matters:
#   "sum"  – extensive quantities (steps, calories, distance, flights)
#   "mean" – intensive quantities (heart rate, weight, blood pressure)
METRIC_META: Dict[str, Dict[str, str]] = {
    "HKQuantityTypeIdentifierStepCount":               {"display": "Steps",                    "agg": "sum",  "category": "activity"},
    "HKQuantityTypeIdentifierFlightsClimbed":           {"display": "Flights Climbed",          "agg": "sum",  "category": "activity"},
    "HKQuantityTypeIdentifierDistanceWalkingRunning":   {"display": "Walking + Running Distance","agg": "sum",  "category": "activity"},
    "HKQuantityTypeIdentifierDistanceCycling":          {"display": "Cycling Distance",         "agg": "sum",  "category": "activity"},
    "HKQuantityTypeIdentifierActiveEnergyBurned":       {"display": "Active Energy",            "agg": "sum",  "category": "activity"},
    "HKQuantityTypeIdentifierBasalEnergyBurned":        {"display": "Basal Energy",             "agg": "sum",  "category": "activity"},
    "HKQuantityTypeIdentifierAppleExerciseTime":        {"display": "Exercise Minutes",         "agg": "sum",  "category": "activity"},
    "HKQuantityTypeIdentifierAppleStandTime":           {"display": "Stand Time",               "agg": "sum",  "category": "activity"},
    "HKQuantityTypeIdentifierHeartRate":                {"display": "Heart Rate",               "agg": "mean", "category": "vitals"},
    "HKQuantityTypeIdentifierRestingHeartRate":         {"display": "Resting Heart Rate",       "agg": "mean", "category": "vitals"},
    "HKQuantityTypeIdentifierHeartRateVariabilitySDNN": {"display": "HRV",                      "agg": "mean", "category": "vitals"},
    "HKQuantityTypeIdentifierOxygenSaturation":        {"display": "Blood Oxygen",             "agg": "mean", "category": "vitals"},
    "HKQuantityTypeIdentifierBloodPressureSystolic":   {"display": "Blood Pressure (Systolic)","agg": "mean", "category": "vitals"},
    "HKQuantityTypeIdentifierBloodPressureDiastolic":  {"display": "Blood Pressure (Diastolic)","agg": "mean","category": "vitals"},
    "HKQuantityTypeIdentifierBodyMass":                {"display": "Weight",                   "agg": "mean", "category": "body"},
    "HKQuantityTypeIdentifierBodyMassIndex":           {"display": "BMI",                      "agg": "mean", "category": "body"},
    "HKQuantityTypeIdentifierBodyFatPercentage":       {"display": "Body Fat %",               "agg": "mean", "category": "body"},
    "HKQuantityTypeIdentifierLeanBodyMass":            {"display": "Lean Body Mass",           "agg": "mean", "category": "body"},
    "HKQuantityTypeIdentifierDietaryEnergyConsumed":   {"display": "Dietary Energy",           "agg": "sum",  "category": "nutrition"},
    "HKQuantityTypeIdentifierDietaryCarbohydrates":    {"display": "Carbohydrates",            "agg": "sum",  "category": "nutrition"},
    "HKQuantityTypeIdentifierDietaryProtein":          {"display": "Protein",                  "agg": "sum",  "category": "nutrition"},
    "HKQuantityTypeIdentifierDietaryFatTotal":         {"display": "Total Fat",                "agg": "sum",  "category": "nutrition"},
    "HKQuantityTypeIdentifierMindfulSession":          {"display": "Mindful Minutes",          "agg": "sum",  "category": "mindfulness"},
    "HKQuantityTypeIdentifierSleepDurationGoal":       {"display": "Sleep Duration Goal",      "agg": "mean", "category": "sleep"},
    "HKCategoryTypeIdentifierSleepAnalysis":           {"display": "Sleep",                    "agg": "sum",  "category": "sleep"},
}

# Human-readable workout type names
WORKOUT_TYPE_NAMES: Dict[str, str] = {
    "HKWorkoutActivityTypeTraditionalStrengthTraining": "Strength Training",
    "HKWorkoutActivityTypeRunning":                     "Running",
    "HKWorkoutActivityTypeCycling":                     "Cycling",
    "HKWorkoutActivityTypeWalking":                     "Walking",
    "HKWorkoutActivityTypeSwimming":                    "Swimming",
    "HKWorkoutActivityTypeHIIT":                        "HIIT",
    "HKWorkoutActivityTypeYoga":                        "Yoga",
    "HKWorkoutActivityTypePilates":                     "Pilates",
    "HKWorkoutActivityTypeElliptical":                  "Elliptical",
    "HKWorkoutActivityTypeRowing":                      "Rowing",
    "HKWorkoutActivityTypeStairClimbing":               "Stair Climbing",
    "HKWorkoutActivityTypeCrossTraining":               "Cross Training",
    "HKWorkoutActivityTypeFunctionalStrengthTraining":  "Functional Strength",
    "HKWorkoutActivityTypeDance":                       "Dance",
    "HKWorkoutActivityTypeBoxing":                      "Boxing",
}


def _metric_id(apple_type: str) -> str:
    """Convert an Apple Health type string to a filesystem-safe metric id."""
    # Strip common prefix families so the id stays short
    name = re.sub(r'^HKQuantityTypeIdentifier', '', apple_type)
    name = re.sub(r'^HKCategoryTypeIdentifier', '', name)
    name = re.sub(r'^HKWorkoutActivityType', '', name)
    # CamelCase → snake_case
    name = re.sub(r'(?<!^)(?=[A-Z])', '_', name).lower()
    return name


def _display_name(apple_type: str) -> str:
    """Return a human-readable display name for a metric type."""
    if apple_type in METRIC_META:
        return METRIC_META[apple_type]["display"]
    # Fall back to splitting CamelCase
    name = re.sub(r'^HKQuantityTypeIdentifier', '', apple_type)
    name = re.sub(r'^HKCategoryTypeIdentifier', '', name)
    name = re.sub(r'(?<!^)(?=[A-Z])', ' ', name)
    return name.strip()


def _workout_display_name(apple_type: str) -> str:
    """Return a human-readable name for a workout activity type."""
    if apple_type in WORKOUT_TYPE_NAMES:
        return WORKOUT_TYPE_NAMES[apple_type]
    name = re.sub(r'^HKWorkoutActivityType', '', apple_type)
    name = re.sub(r'(?<!^)(?=[A-Z])', ' ', name)
    return name.strip()


class HealthDataExporter:
    """
    Exports a list of HealthRecord objects to a structured set of JSON files
    that can be consumed by a static HTML dashboard.
    """

    def __init__(self, records: List[HealthRecord], output_dir: Path):
        self.records = records
        self.output_dir = output_dir
        self.data_dir = output_dir / "data"
        self.metrics_dir = self.data_dir / "metrics"

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------

    def export(self) -> None:
        """Run the full export pipeline."""
        self._prepare_directories()

        df = self._to_dataframe()

        # Split into workouts and quantity/category records
        workout_df = df[df["record_type"].str.startswith("Workout:")].copy()
        metric_df  = df[~df["record_type"].str.startswith("Workout:")].copy()

        metric_manifest_entries = self._export_metrics(metric_df)
        workout_summary = self._export_workouts(workout_df)
        self._export_manifest(metric_manifest_entries, workout_summary, df)

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------

    def _prepare_directories(self) -> None:
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.metrics_dir.mkdir(parents=True, exist_ok=True)

    def _to_dataframe(self) -> pd.DataFrame:
        """Convert list of HealthRecord to a pandas DataFrame."""
        rows = []
        for r in self.records:
            rows.append({
                "record_type": r.record_type,
                "source":      r.source,
                "unit":        r.unit,
                "value":       r.value,
                "start_date":  r.start_date,
                "end_date":    r.end_date,
                "metadata":    r.metadata,
            })
        df = pd.DataFrame(rows)
        if not df.empty:
            df["start_date"] = pd.to_datetime(df["start_date"])
            df["date"] = df["start_date"].dt.date
        return df

    # ------------------------------------------------------------------
    # Metric export
    # ------------------------------------------------------------------

    def _export_metrics(self, df: pd.DataFrame) -> List[Dict[str, Any]]:
        """Write one JSON file per metric type; return manifest entries."""
        if df.empty:
            return []

        manifest_entries = []

        for apple_type, group in df.groupby("record_type"):
            meta  = METRIC_META.get(apple_type, {})
            agg   = meta.get("agg", self._infer_agg(group))
            mid   = _metric_id(apple_type)
            dname = _display_name(apple_type)
            unit  = group["unit"].dropna().mode()
            unit  = unit.iloc[0] if not unit.empty else ""

            daily   = self._aggregate_daily(group, agg)
            weekly  = self._aggregate_weekly(daily, agg)
            monthly = self._aggregate_monthly(daily, agg)

            payload = {
                "metric_id":    mid,
                "display_name": dname,
                "apple_type":   apple_type,
                "unit":         unit,
                "agg_method":   agg,
                "category":     meta.get("category", "other"),
                "date_range": {
                    "start": str(daily[0]["date"])  if daily   else None,
                    "end":   str(daily[-1]["date"]) if daily   else None,
                },
                "record_count": len(group),
                "daily":   daily,
                "weekly":  weekly,
                "monthly": monthly,
            }

            out_path = self.metrics_dir / f"{mid}.json"
            self._write_json(out_path, payload)

            manifest_entries.append({
                "id":           mid,
                "display_name": dname,
                "apple_type":   apple_type,
                "unit":         unit,
                "agg_method":   agg,
                "category":     meta.get("category", "other"),
                "record_count": len(group),
                "date_range": payload["date_range"],
            })

        # Sort by record count descending so the most data-rich metrics
        # appear first in the sidebar
        manifest_entries.sort(key=lambda x: x["record_count"], reverse=True)
        return manifest_entries

    def _infer_agg(self, group: pd.DataFrame) -> str:
        """Heuristic: if unit looks like a count/total, use sum; else mean."""
        unit = group["unit"].dropna().mode()
        unit = unit.iloc[0].lower() if not unit.empty else ""
        sum_units = {"count", "kcal", "cal", "km", "mi", "m", "steps", "flights"}
        if any(u in unit for u in sum_units):
            return "sum"
        return "mean"

    def _aggregate_daily(
        self, group: pd.DataFrame, agg: str
    ) -> List[Dict[str, Any]]:
        """Aggregate records to one row per calendar day."""
        g = group.groupby("date")["value"]
        if agg == "sum":
            agg_series = g.sum()
        else:
            agg_series = g.mean()

        min_series   = g.min()
        max_series   = g.max()
        count_series = g.count()

        result = []
        for d in sorted(agg_series.index):
            result.append({
                "date":  str(d),
                "value": round(float(agg_series[d]), 4),
                "min":   round(float(min_series[d]),   4),
                "max":   round(float(max_series[d]),   4),
                "count": int(count_series[d]),
            })
        return result

    def _aggregate_weekly(
        self, daily: List[Dict[str, Any]], agg: str
    ) -> List[Dict[str, Any]]:
        """Roll up daily rows into ISO week buckets."""
        if not daily:
            return []

        week_map: Dict[str, List[float]] = {}
        week_start: Dict[str, str] = {}

        for row in daily:
            d = date.fromisoformat(row["date"])
            iso_year, iso_week, _ = d.isocalendar()
            key = f"{iso_year}-W{iso_week:02d}"
            week_map.setdefault(key, []).append(row["value"])
            # Track the Monday of that week
            monday = d - timedelta(days=d.weekday())
            week_start.setdefault(key, str(monday))

        result = []
        for key in sorted(week_map.keys()):
            vals = week_map[key]
            value = sum(vals) if agg == "sum" else sum(vals) / len(vals)
            result.append({
                "week":       key,
                "start_date": week_start[key],
                "value":      round(value, 4),
                "count":      len(vals),
            })
        return result

    def _aggregate_monthly(
        self, daily: List[Dict[str, Any]], agg: str
    ) -> List[Dict[str, Any]]:
        """Roll up daily rows into calendar-month buckets."""
        if not daily:
            return []

        month_map: Dict[str, List[float]] = {}

        for row in daily:
            key = row["date"][:7]  # "YYYY-MM"
            month_map.setdefault(key, []).append(row["value"])

        result = []
        for key in sorted(month_map.keys()):
            vals = month_map[key]
            value = sum(vals) if agg == "sum" else sum(vals) / len(vals)
            result.append({
                "month":      key,
                "start_date": key + "-01",
                "value":      round(value, 4),
                "count":      len(vals),
            })
        return result

    # ------------------------------------------------------------------
    # Workout export
    # ------------------------------------------------------------------

    def _export_workouts(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Write workouts.json; return a summary dict for the manifest."""
        if df.empty:
            return {"total": 0, "types": [], "date_range": {"start": None, "end": None}}

        records_out = []
        for _, row in df.sort_values("start_date").iterrows():
            meta         = row.get("metadata") or {}
            apple_type   = meta.get("workout_type", row["record_type"].replace("Workout:", ""))
            display_type = _workout_display_name(apple_type)
            records_out.append({
                "date":             str(row["date"]),
                "type":             display_type,
                "apple_type":       apple_type,
                "duration_minutes": round(float(row["value"]), 2),
                "calories":         _safe_float(meta.get("total_energy_burned")),
                "distance":         _safe_float(meta.get("total_distance")),
                "distance_unit":    meta.get("total_distance_unit"),
                "source":           row["source"],
            })

        # Per-type summary
        by_type: Dict[str, Any] = {}
        for rec in records_out:
            t = rec["type"]
            by_type.setdefault(t, {"count": 0, "total_duration_minutes": 0.0, "total_calories": 0.0})
            by_type[t]["count"] += 1
            by_type[t]["total_duration_minutes"] += rec["duration_minutes"]
            if rec["calories"]:
                by_type[t]["total_calories"] += rec["calories"]

        for t, stats in by_type.items():
            stats["avg_duration_minutes"] = round(
                stats["total_duration_minutes"] / stats["count"], 2
            )
            stats["total_duration_minutes"] = round(stats["total_duration_minutes"], 2)
            stats["total_calories"]         = round(stats["total_calories"],         2)

        dates = sorted(r["date"] for r in records_out)
        summary = {
            "total":      len(records_out),
            "types":      sorted(by_type.keys()),
            "date_range": {"start": dates[0], "end": dates[-1]},
        }

        payload = {**summary, "by_type": by_type, "records": records_out}
        self._write_json(self.data_dir / "workouts.json", payload)
        return summary

    # ------------------------------------------------------------------
    # Manifest
    # ------------------------------------------------------------------

    def _export_manifest(
        self,
        metric_entries: List[Dict[str, Any]],
        workout_summary: Dict[str, Any],
        full_df: pd.DataFrame,
    ) -> None:
        """Write manifest.json – the first file the dashboard loads."""
        date_range: Dict[str, Optional[str]] = {"start": None, "end": None}
        if not full_df.empty and "start_date" in full_df.columns:
            valid = full_df["start_date"].dropna()
            if not valid.empty:
                date_range["start"] = str(valid.min().date())
                date_range["end"]   = str(valid.max().date())

        sources = (
            sorted(full_df["source"].dropna().unique().tolist())
            if not full_df.empty
            else []
        )

        manifest = {
            "generated_at":   datetime.utcnow().isoformat() + "Z",
            "date_range":     date_range,
            "total_records":  len(self.records),
            "metrics":        metric_entries,
            "workouts":       workout_summary,
            "sources":        sources,
        }
        self._write_json(self.data_dir / "manifest.json", manifest)

    # ------------------------------------------------------------------
    # Utility
    # ------------------------------------------------------------------

    @staticmethod
    def _write_json(path: Path, data: Any) -> None:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, separators=(",", ":"), default=str)


def _safe_float(value: Any) -> Optional[float]:
    """Convert a value to float, returning None on failure."""
    if value is None:
        return None
    try:
        return round(float(value), 2)
    except (ValueError, TypeError):
        return None
